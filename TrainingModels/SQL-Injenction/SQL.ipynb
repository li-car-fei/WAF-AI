{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;\"> SQL Injection + </h1>\n",
    "<span> Chou@ibCher+</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_3044\\3123394498.py\", line 1, in <module>\n",
      "    import pandas as pd\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py\", line 26, in <module>\n",
      "    from pandas.compat import (\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\compat\\__init__.py\", line 27, in <module>\n",
      "    from pandas.compat.pyarrow import (\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\compat\\pyarrow.py\", line 8, in <module>\n",
      "    import pyarrow as pa\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pyarrow\\__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_3044\\3123394498.py\", line 1, in <module>\n",
      "    import pandas as pd\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\api.py\", line 9, in <module>\n",
      "    from pandas.core.dtypes.dtypes import (\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\dtypes.py\", line 24, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pyarrow\\__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "# machine learning models\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# ensemble learning\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier, StackingClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: c:\\Users\\LENOVO\\Documents\\GitHub\\WAF-AI\n",
      "Data distribution\n",
      "injection_type\n",
      "LEGAL    15257\n",
      "SQL       3288\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Correct the path\n",
    "current_dir = os.getcwd()  \n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..', '..'))\n",
    "print('Current directory:', parent_dir)\n",
    "\n",
    "# Define the file path\n",
    "df_path = os.path.join(parent_dir, 'data', 'processed', 'sqli-by-chou@ibcher+.csv')\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(df_path, usecols=['payload', 'is_malicious', 'injection_type'])\n",
    "\n",
    "\n",
    "print('Data distribution')\n",
    "print(df['injection_type'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "df = pd.read_csv(df_path, usecols=['payload', 'is_malicious', 'injection_type'])\n",
    "\n",
    "# Convert the 'payload' column to strings and fill NaN values\n",
    "df['payload'] = df['payload'].astype(str).fillna('')\n",
    "\n",
    "# Remove any empty data points\n",
    "df = df[df['payload'] != '']\n",
    "\n",
    "# Remove any duplicate payloads\n",
    "df = df.drop_duplicates(subset=['payload'])\n",
    "\n",
    "# Custom tokenization function to capture SQL injection patterns\n",
    "def custom_tokenizer(text):\n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "# Initialize the Count Vectorizer (Bag of Words) with custom tokenizer and n-grams\n",
    "count_vectorizer = CountVectorizer(min_df=1, tokenizer=custom_tokenizer, ngram_range=(1, 3))\n",
    "\n",
    "# Transform the 'payload' column\n",
    "X = count_vectorizer.fit_transform(df['payload'])\n",
    "\n",
    "# Define the target variable\n",
    "y = df['is_malicious']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9599090133636622\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      3062\n",
      "           1       1.00      0.69      0.82       455\n",
      "\n",
      "    accuracy                           0.96      3517\n",
      "   macro avg       0.98      0.85      0.90      3517\n",
      "weighted avg       0.96      0.96      0.96      3517\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Train the classifier\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.9599090133636622\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      3062\n",
      "           1       0.99      0.69      0.82       455\n",
      "\n",
      "    accuracy                           0.96      3517\n",
      "   macro avg       0.98      0.85      0.90      3517\n",
      "weighted avg       0.96      0.96      0.96      3517\n",
      "\n",
      "Logistic Regression Accuracy: 0.9556440147853285\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      3062\n",
      "           1       1.00      0.66      0.79       455\n",
      "\n",
      "    accuracy                           0.96      3517\n",
      "   macro avg       0.98      0.83      0.88      3517\n",
      "weighted avg       0.96      0.96      0.95      3517\n",
      "\n",
      "Decision Tree Accuracy: 0.9596246801251066\n",
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      3062\n",
      "           1       1.00      0.69      0.82       455\n",
      "\n",
      "    accuracy                           0.96      3517\n",
      "   macro avg       0.98      0.84      0.90      3517\n",
      "weighted avg       0.96      0.96      0.96      3517\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the classifiers\n",
    "svm_classifier = SVC()\n",
    "logistic_regression_classifier = LogisticRegression(max_iter=1000)\n",
    "decision_tree_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Train the classifiers\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "logistic_regression_classifier.fit(X_train, y_train)\n",
    "decision_tree_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_svm = svm_classifier.predict(X_test)\n",
    "y_pred_logistic = logistic_regression_classifier.predict(X_test)\n",
    "y_pred_tree = decision_tree_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the classifiers\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "accuracy_logistic = accuracy_score(y_test, y_pred_logistic)\n",
    "accuracy_tree = accuracy_score(y_test, y_pred_tree)\n",
    "\n",
    "report_svm = classification_report(y_test, y_pred_svm)\n",
    "report_logistic = classification_report(y_test, y_pred_logistic)\n",
    "report_tree = classification_report(y_test, y_pred_tree)\n",
    "\n",
    "print(f'SVM Accuracy: {accuracy_svm}')\n",
    "print('SVM Classification Report:')\n",
    "print(report_svm)\n",
    "\n",
    "print(f'Logistic Regression Accuracy: {accuracy_logistic}')\n",
    "print('Logistic Regression Classification Report:')\n",
    "print(report_logistic)\n",
    "\n",
    "print(f'Decision Tree Accuracy: {accuracy_tree}')\n",
    "print('Decision Tree Classification Report:')\n",
    "print(report_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 color='red'>Ensemble learning</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Accuracy: 0.959340346886551\n",
      "Bagging Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      3062\n",
      "           1       1.00      0.69      0.81       455\n",
      "\n",
      "    accuracy                           0.96      3517\n",
      "   macro avg       0.98      0.84      0.90      3517\n",
      "weighted avg       0.96      0.96      0.96      3517\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boosting Accuracy: 0.959340346886551\n",
      "Boosting Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      3062\n",
      "           1       1.00      0.69      0.81       455\n",
      "\n",
      "    accuracy                           0.96      3517\n",
      "   macro avg       0.98      0.84      0.90      3517\n",
      "weighted avg       0.96      0.96      0.96      3517\n",
      "\n",
      "Random Forest Accuracy: 0.9587716804094398\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      3062\n",
      "           1       1.00      0.68      0.81       455\n",
      "\n",
      "    accuracy                           0.96      3517\n",
      "   macro avg       0.98      0.84      0.89      3517\n",
      "weighted avg       0.96      0.96      0.96      3517\n",
      "\n",
      "Stacking Accuracy: 0.960762013079329\n",
      "Stacking Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      3062\n",
      "           1       0.99      0.70      0.82       455\n",
      "\n",
      "    accuracy                           0.96      3517\n",
      "   macro avg       0.98      0.85      0.90      3517\n",
      "weighted avg       0.96      0.96      0.96      3517\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Bagging\n",
    "bagging_classifier = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
    "bagging_classifier.fit(X_train, y_train)\n",
    "y_pred_bagging = bagging_classifier.predict(X_test)\n",
    "accuracy_bagging = accuracy_score(y_test, y_pred_bagging)\n",
    "report_bagging = classification_report(y_test, y_pred_bagging)\n",
    "\n",
    "print(f'Bagging Accuracy: {accuracy_bagging}')\n",
    "print('Bagging Classification Report:')\n",
    "print(report_bagging)\n",
    "\n",
    "# Boosting (AdaBoost)\n",
    "boosting_classifier = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
    "boosting_classifier.fit(X_train, y_train)\n",
    "y_pred_boosting = boosting_classifier.predict(X_test)\n",
    "accuracy_boosting = accuracy_score(y_test, y_pred_boosting)\n",
    "report_boosting = classification_report(y_test, y_pred_boosting)\n",
    "\n",
    "print(f'Boosting Accuracy: {accuracy_boosting}')\n",
    "print('Boosting Classification Report:')\n",
    "print(report_boosting)\n",
    "\n",
    "# Random Forest\n",
    "random_forest_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest_classifier.fit(X_train, y_train)\n",
    "y_pred_rf = random_forest_classifier.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "report_rf = classification_report(y_test, y_pred_rf)\n",
    "\n",
    "print(f'Random Forest Accuracy: {accuracy_rf}')\n",
    "print('Random Forest Classification Report:')\n",
    "print(report_rf)\n",
    "\n",
    "# Stacking\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=50, random_state=42)),\n",
    "    ('svr', SVC(probability=True, random_state=42))\n",
    "]\n",
    "stacking_classifier = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "stacking_classifier.fit(X_train, y_train)\n",
    "y_pred_stacking = stacking_classifier.predict(X_test)\n",
    "accuracy_stacking = accuracy_score(y_test, y_pred_stacking)\n",
    "report_stacking = classification_report(y_test, y_pred_stacking)\n",
    "\n",
    "print(f'Stacking Accuracy: {accuracy_stacking}')\n",
    "print('Stacking Classification Report:')\n",
    "print(report_stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Saving the model and vectorizer</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modelPathSaving = os.path.join(parent_dir, 'WAF', 'nb.pkl')\n",
    "vectorizerPathSaving = os.path.join(parent_dir, 'WAF', 'vectorizer.pkl')\n",
    "\n",
    "joblib.dump(nb_classifier, modelPathSaving)\n",
    "joblib.dump(count_vectorizer, vectorizerPathSaving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Injection: verve -> Prediction: 0\n",
      "SQL Injection: helllo chouaib -> Prediction: 0\n",
      "SQL Injection: username -> Prediction: 0\n",
      "SQL Injection: password -> Prediction: 0\n",
      "SQL Injection: bounjour -> Prediction: 0\n",
      "SQL Injection: 1' OR '1'='1 -> Prediction: 1\n",
      "SQL Injection: 1' OR '1'='1' -- -> Prediction: 1\n",
      "SQL Injection: 1' OR '1'='1' ({ -> Prediction: 1\n",
      "SQL Injection: 1' OR '1'='1' /* -> Prediction: 1\n",
      "SQL Injection: 1' OR '1'='1' # -> Prediction: 1\n",
      "SQL Injection: 1' OR '1'='1' AND '1'='1 -> Prediction: 1\n",
      "SQL Injection: 1' OR '1'='1' AND '1'='2 -> Prediction: 1\n",
      "SQL Injection: 1' OR '1'='1' UNION SELECT NULL, NULL -> Prediction: 1\n",
      "SQL Injection: 1' OR '1'='1' UNION SELECT username, password FROM users -> Prediction: 1\n",
      "SQL Injection: 1' OR '1'='1' UNION SELECT table_name, column_name FROM information_schema.columns -> Prediction: 1\n"
     ]
    }
   ],
   "source": [
    "# SQL injection examples\n",
    "sql_injections = [\n",
    "    'verve',\n",
    "    'helllo chouaib',\n",
    "    'username',\n",
    "    'password',\n",
    "    'bounjour',\n",
    "    \"1' OR '1'='1\",\n",
    "    \"1' OR '1'='1' --\",\n",
    "    \"1' OR '1'='1' ({\",\n",
    "    \"1' OR '1'='1' /*\",\n",
    "    \"1' OR '1'='1' #\",\n",
    "    \"1' OR '1'='1' AND '1'='1\",\n",
    "    \"1' OR '1'='1' AND '1'='2\",\n",
    "    \"1' OR '1'='1' UNION SELECT NULL, NULL\",\n",
    "    \"1' OR '1'='1' UNION SELECT username, password FROM users\",\n",
    "    \"1' OR '1'='1' UNION SELECT table_name, column_name FROM information_schema.columns\"\n",
    "]\n",
    "\n",
    "# Transform the SQL injections using the vectorizer\n",
    "sql_injections_vectorized = count_vectorizer.transform(sql_injections).toarray()\n",
    "\n",
    "# Predict using the Naive Bayes model\n",
    "predictions = nb_classifier.predict(sql_injections_vectorized)\n",
    "\n",
    "# Print the predictions\n",
    "for i, sql in enumerate(sql_injections):\n",
    "    print(f\"SQL Injection: {sql} -> Prediction: {predictions[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
