{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;\"> SQL Injection + </h1>\n",
    "<span> Chou@ibCher+</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "# machine learning models\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# ensemble learning\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier, StackingClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: c:\\Users\\LENOVO\\Documents\\GitHub\\WAF-AI\n",
      "Data distribution\n",
      "injection_type\n",
      "LEGAL    15257\n",
      "SQL       3288\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Correct the path\n",
    "current_dir = os.getcwd()  \n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..', '..'))\n",
    "print('Current directory:', parent_dir)\n",
    "\n",
    "# Define the file path\n",
    "df_path = os.path.join(parent_dir, 'data', 'processed', 'cleanedData.csv')\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(df_path, usecols=['payload', 'is_malicious', 'injection_type'])\n",
    "\n",
    "\n",
    "print('Data distribution')\n",
    "print(df['injection_type'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "df = pd.read_csv(df_path, usecols=['payload', 'is_malicious', 'injection_type'])\n",
    "\n",
    "# Convert the 'payload' column to strings and fill NaN values\n",
    "df['payload'] = df['payload'].astype(str).fillna('')\n",
    "\n",
    "# Remove any empty data points\n",
    "df = df[df['payload'] != '']\n",
    "\n",
    "# Remove any duplicate payloads\n",
    "df = df.drop_duplicates(subset=['payload'])\n",
    "\n",
    "# Custom tokenization function to capture SQL injection patterns\n",
    "def custom_tokenizer(text):\n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "# Initialize the Count Vectorizer (Bag of Words) with custom tokenizer and n-grams\n",
    "count_vectorizer = CountVectorizer(min_df=1, tokenizer=custom_tokenizer, ngram_range=(1, 3))\n",
    "\n",
    "# Transform the 'payload' column\n",
    "X = count_vectorizer.fit_transform(df['payload'])\n",
    "\n",
    "# Define the target variable\n",
    "y = df['is_malicious']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9599090133636622\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      3062\n",
      "           1       1.00      0.69      0.82       455\n",
      "\n",
      "    accuracy                           0.96      3517\n",
      "   macro avg       0.98      0.85      0.90      3517\n",
      "weighted avg       0.96      0.96      0.96      3517\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Train the classifier\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.9599090133636622\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      3062\n",
      "           1       0.99      0.69      0.82       455\n",
      "\n",
      "    accuracy                           0.96      3517\n",
      "   macro avg       0.98      0.85      0.90      3517\n",
      "weighted avg       0.96      0.96      0.96      3517\n",
      "\n",
      "Logistic Regression Accuracy: 0.9556440147853285\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      3062\n",
      "           1       1.00      0.66      0.79       455\n",
      "\n",
      "    accuracy                           0.96      3517\n",
      "   macro avg       0.98      0.83      0.88      3517\n",
      "weighted avg       0.96      0.96      0.95      3517\n",
      "\n",
      "Decision Tree Accuracy: 0.9596246801251066\n",
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      3062\n",
      "           1       1.00      0.69      0.82       455\n",
      "\n",
      "    accuracy                           0.96      3517\n",
      "   macro avg       0.98      0.84      0.90      3517\n",
      "weighted avg       0.96      0.96      0.96      3517\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the classifiers\n",
    "svm_classifier = SVC()\n",
    "logistic_regression_classifier = LogisticRegression(max_iter=1000)\n",
    "decision_tree_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Train the classifiers\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "logistic_regression_classifier.fit(X_train, y_train)\n",
    "decision_tree_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_svm = svm_classifier.predict(X_test)\n",
    "y_pred_logistic = logistic_regression_classifier.predict(X_test)\n",
    "y_pred_tree = decision_tree_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the classifiers\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "accuracy_logistic = accuracy_score(y_test, y_pred_logistic)\n",
    "accuracy_tree = accuracy_score(y_test, y_pred_tree)\n",
    "\n",
    "report_svm = classification_report(y_test, y_pred_svm)\n",
    "report_logistic = classification_report(y_test, y_pred_logistic)\n",
    "report_tree = classification_report(y_test, y_pred_tree)\n",
    "\n",
    "print(f'SVM Accuracy: {accuracy_svm}')\n",
    "print('SVM Classification Report:')\n",
    "print(report_svm)\n",
    "\n",
    "print(f'Logistic Regression Accuracy: {accuracy_logistic}')\n",
    "print('Logistic Regression Classification Report:')\n",
    "print(report_logistic)\n",
    "\n",
    "print(f'Decision Tree Accuracy: {accuracy_tree}')\n",
    "print('Decision Tree Classification Report:')\n",
    "print(report_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 color='red'>Ensemble learning</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Accuracy: 0.959340346886551\n",
      "Bagging Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      3062\n",
      "           1       1.00      0.69      0.81       455\n",
      "\n",
      "    accuracy                           0.96      3517\n",
      "   macro avg       0.98      0.84      0.90      3517\n",
      "weighted avg       0.96      0.96      0.96      3517\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boosting Accuracy: 0.959340346886551\n",
      "Boosting Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      3062\n",
      "           1       1.00      0.69      0.81       455\n",
      "\n",
      "    accuracy                           0.96      3517\n",
      "   macro avg       0.98      0.84      0.90      3517\n",
      "weighted avg       0.96      0.96      0.96      3517\n",
      "\n",
      "Random Forest Accuracy: 0.9587716804094398\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      3062\n",
      "           1       1.00      0.68      0.81       455\n",
      "\n",
      "    accuracy                           0.96      3517\n",
      "   macro avg       0.98      0.84      0.89      3517\n",
      "weighted avg       0.96      0.96      0.96      3517\n",
      "\n",
      "Stacking Accuracy: 0.960762013079329\n",
      "Stacking Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      3062\n",
      "           1       0.99      0.70      0.82       455\n",
      "\n",
      "    accuracy                           0.96      3517\n",
      "   macro avg       0.98      0.85      0.90      3517\n",
      "weighted avg       0.96      0.96      0.96      3517\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Bagging\n",
    "bagging_classifier = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
    "bagging_classifier.fit(X_train, y_train)\n",
    "y_pred_bagging = bagging_classifier.predict(X_test)\n",
    "accuracy_bagging = accuracy_score(y_test, y_pred_bagging)\n",
    "report_bagging = classification_report(y_test, y_pred_bagging)\n",
    "\n",
    "print(f'Bagging Accuracy: {accuracy_bagging}')\n",
    "print('Bagging Classification Report:')\n",
    "print(report_bagging)\n",
    "\n",
    "# Boosting (AdaBoost)\n",
    "boosting_classifier = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
    "boosting_classifier.fit(X_train, y_train)\n",
    "y_pred_boosting = boosting_classifier.predict(X_test)\n",
    "accuracy_boosting = accuracy_score(y_test, y_pred_boosting)\n",
    "report_boosting = classification_report(y_test, y_pred_boosting)\n",
    "\n",
    "print(f'Boosting Accuracy: {accuracy_boosting}')\n",
    "print('Boosting Classification Report:')\n",
    "print(report_boosting)\n",
    "\n",
    "# Random Forest\n",
    "random_forest_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest_classifier.fit(X_train, y_train)\n",
    "y_pred_rf = random_forest_classifier.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "report_rf = classification_report(y_test, y_pred_rf)\n",
    "\n",
    "print(f'Random Forest Accuracy: {accuracy_rf}')\n",
    "print('Random Forest Classification Report:')\n",
    "print(report_rf)\n",
    "\n",
    "# Stacking\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=50, random_state=42)),\n",
    "    ('svr', SVC(probability=True, random_state=42))\n",
    "]\n",
    "stacking_classifier = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "stacking_classifier.fit(X_train, y_train)\n",
    "y_pred_stacking = stacking_classifier.predict(X_test)\n",
    "accuracy_stacking = accuracy_score(y_test, y_pred_stacking)\n",
    "report_stacking = classification_report(y_test, y_pred_stacking)\n",
    "\n",
    "print(f'Stacking Accuracy: {accuracy_stacking}')\n",
    "print('Stacking Classification Report:')\n",
    "print(report_stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Saving the model and vectorizer</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modelPathSaving = os.path.join(parent_dir, 'WAF', 'nb.pkl')\n",
    "vectorizerPathSaving = os.path.join(parent_dir, 'WAF', 'vectorizer.pkl')\n",
    "\n",
    "joblib.dump(nb_classifier, modelPathSaving)\n",
    "joblib.dump(count_vectorizer, vectorizerPathSaving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Injection: verve -> Prediction: 0\n",
      "SQL Injection: helllo chouaib -> Prediction: 0\n",
      "SQL Injection: username -> Prediction: 0\n",
      "SQL Injection: password -> Prediction: 0\n",
      "SQL Injection: bounjour -> Prediction: 0\n",
      "SQL Injection: 1' OR '1'='1 -> Prediction: 1\n",
      "SQL Injection: 1' OR '1'='1' -- -> Prediction: 1\n",
      "SQL Injection: 1' OR '1'='1' ({ -> Prediction: 1\n",
      "SQL Injection: 1' OR '1'='1' /* -> Prediction: 1\n",
      "SQL Injection: 1' OR '1'='1' # -> Prediction: 1\n",
      "SQL Injection: 1' OR '1'='1' AND '1'='1 -> Prediction: 1\n",
      "SQL Injection: 1' OR '1'='1' AND '1'='2 -> Prediction: 1\n",
      "SQL Injection: 1' OR '1'='1' UNION SELECT NULL, NULL -> Prediction: 1\n",
      "SQL Injection: 1' OR '1'='1' UNION SELECT username, password FROM users -> Prediction: 1\n",
      "SQL Injection: 1' OR '1'='1' UNION SELECT table_name, column_name FROM information_schema.columns -> Prediction: 1\n"
     ]
    }
   ],
   "source": [
    "# SQL injection examples\n",
    "sql_injections = [\n",
    "    'verve',\n",
    "    'helllo chouaib',\n",
    "    'username',\n",
    "    'password',\n",
    "    'bounjour',\n",
    "    \"1' OR '1'='1\",\n",
    "    \"1' OR '1'='1' --\",\n",
    "    \"1' OR '1'='1' ({\",\n",
    "    \"1' OR '1'='1' /*\",\n",
    "    \"1' OR '1'='1' #\",\n",
    "    \"1' OR '1'='1' AND '1'='1\",\n",
    "    \"1' OR '1'='1' AND '1'='2\",\n",
    "    \"1' OR '1'='1' UNION SELECT NULL, NULL\",\n",
    "    \"1' OR '1'='1' UNION SELECT username, password FROM users\",\n",
    "    \"1' OR '1'='1' UNION SELECT table_name, column_name FROM information_schema.columns\"\n",
    "]\n",
    "\n",
    "# Transform the SQL injections using the vectorizer\n",
    "sql_injections_vectorized = count_vectorizer.transform(sql_injections).toarray()\n",
    "\n",
    "# Predict using the Naive Bayes model\n",
    "predictions = nb_classifier.predict(sql_injections_vectorized)\n",
    "\n",
    "# Print the predictions\n",
    "for i, sql in enumerate(sql_injections):\n",
    "    print(f\"SQL Injection: {sql} -> Prediction: {predictions[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
